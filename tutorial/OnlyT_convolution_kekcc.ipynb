{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55e341b",
   "metadata": {},
   "source": [
    "# **<font color=\"red\"> This notebook is designed to run on kekcc. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f22939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'matplotlib.pyplot' from '/home/cmb/naganoy/.julia/conda/3/lib/python3.8/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Condor\n",
    "using NPZ\n",
    "using Healpix\n",
    "using Plots\n",
    "using PyCall\n",
    "using Falcons\n",
    "using PyPlot\n",
    "using DataFrames\n",
    "\n",
    "hp = pyimport(\"healpy\")\n",
    "np = pyimport(\"numpy\")\n",
    "plt = pyimport(\"matplotlib.pyplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce4b768",
   "metadata": {},
   "source": [
    "### Set the Healpix parameters to be used in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde355a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside=128\n",
    "npix = nside2npix(nside)\n",
    "res = Resolution(nside)\n",
    "lmax = 3*nside-1\n",
    "mmax = 3*nside-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daf0447",
   "metadata": {},
   "source": [
    "### Here, as an example, the sky and beam used in PTEP are used for the calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff73ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×134655 Matrix{ComplexF64}:\n",
       " 0.101997+0.0im  0.176581+0.0im  0.227776+0.0im  …  1.34001e-9+8.83946e-10im\n",
       "      0.0+0.0im       0.0+0.0im       0.0+0.0im            0.0+0.0im\n",
       "      0.0+0.0im       0.0+0.0im       0.0+0.0im            0.0+0.0im"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alm_path=\"/gpfs/group/cmb/litebird/usr/wangw/d0s0/alm_LB_HFT_195_PTEP_20200915_compsep.fits\"\n",
    "blm_path=\"/gpfs/group/cmb/litebird/usr/wangw/output_wang/beam/blm/fc/H1-195/blm_H00_120_Q_195B_I000.fits\"\n",
    "alm_LB_HFT_195_PTEP_20200915_compsep=ComplexF64.(hp.read_alm(alm_path, hdu = [1,2,3]))\n",
    "blm_H00_120_Q_195B_I000=ComplexF64.(hp.read_alm(blm_path, hdu = [1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158ec27",
   "metadata": {},
   "source": [
    "### In PTEP, nside=512 for both sky and beam, plus lmax=1024 and mmax=140 for beam. \n",
    "### The operation is performed to change this to correspond to nside=128, which is used in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea3b3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "function truncate_alm(alm, lmax, mmax)\n",
    "    alm_new = Alm(lmax,mmax)\n",
    "    size = numberOfAlms(lmax, min(mmax,alm.mmax))\n",
    "    for idx in 1:size\n",
    "        m = convert(Int64, ceil(((2 * lmax + 1) - sqrt((2 * lmax + 1) ^ 2 - 8 * (idx - 1 - lmax))) / 2))\n",
    "        l = idx - 1 - m * div(2 * lmax + 1 - m,2)\n",
    "        alm_new.alm[idx] = alm.alm[almIndex(alm, l, m)]\n",
    "    end\n",
    "    return alm_new\n",
    "end\n",
    "\n",
    "py\"\"\"def truncate_alm(alms, lmax = -1, mmax = -1, mmax_in=-1):\n",
    "    import healpy as hp\n",
    "    import numpy as np\n",
    "    l2max = hp.Alm.getlmax(alms.shape[-1], mmax=mmax_in)\n",
    "    if lmax != -1 and lmax > l2max:\n",
    "        raise ValueError(\"Too big lmax in parameter\")\n",
    "    elif lmax == -1:\n",
    "        lmax = l2max\n",
    "\n",
    "    if mmax_in == -1:\n",
    "        mmax_in = l2max\n",
    "\n",
    "    if mmax == -1:\n",
    "        mmax = lmax\n",
    "    if mmax > mmax_in:\n",
    "        mmax = mmax_in\n",
    "\n",
    "    # if out_dtype is None:\n",
    "    #     out_dtype = alms[0].real.dtype\n",
    "\n",
    "    l, m = hp.Alm.getlm(lmax)\n",
    "    idx = np.where((l <= lmax) * (m <= mmax))\n",
    "    l = l[idx]\n",
    "    m = m[idx]\n",
    "\n",
    "    idx_in_original = hp.Alm.getidx(l2max, l=l, m=m)\n",
    "    \n",
    "    return alms[..., idx_in_original]\n",
    "\"\"\"\n",
    "\n",
    "py\"\"\"def pad_alm(alms, mmax_in = -1):\n",
    "    import healpy as hp\n",
    "    import numpy as np\n",
    "    lmax = hp.Alm.getlmax(alms.shape[-1], mmax=mmax_in)\n",
    "    lm_size = hp.Alm.getsize(lmax)\n",
    "    alms_new = np.zeros((alms.shape[:-1])+(lm_size,), dtype=alms.dtype)\n",
    "    alms_new[..., :alms.shape[-1]] = alms\n",
    "    return alms_new \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b9b312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_alm=py\"pad_alm\"(alm_LB_HFT_195_PTEP_20200915_compsep, mmax_in=3*512)\n",
    "alm=py\"truncate_alm\"(pad_alm, lmax = lmax, mmax = lmax)\n",
    "pad_blm=py\"pad_alm\"(blm_H00_120_Q_195B_I000, mmax_in=140)\n",
    "blm=py\"truncate_alm\"(pad_blm, lmax = lmax, mmax = mmax)\n",
    "unique_θ = unique_theta(npix, res);\n",
    "\n",
    "np.save(\"alm_test\", alm)\n",
    "np.save(\"blm_test\",blm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9d5f6",
   "metadata": {},
   "source": [
    "### Specify the PATH of parameters such as alm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0e8643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"./hoge\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alm_path = \"./test_alm.npy\"\n",
    "blm_path = \"./test_blm.npy\"\n",
    "dir_path = \"./hoge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fba67a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open( \"convolve_T.jl\", \"w\" ) do fp\n",
    "    \n",
    "write( fp, \"\"\"using Condor\n",
    "using NPZ\n",
    "using Healpix\n",
    "using DataFrames\n",
    "using Falcons\n",
    "using PyCall\n",
    "np=pyimport(\"numpy\")\n",
    "\n",
    "# standard input\n",
    "idx=parse(Int64, ARGS[1]) # Specifies a piece of sky with unique θ\n",
    "nside = parse(Int64, ARGS[2]) # Specify nside\n",
    "dir_save = ARGS[3] # Specify preconvolved-map path\n",
    "alm_path=ARGS[4]\n",
    "blm_path=ARGS[5]\n",
    "        \n",
    "# path of save file\n",
    "dir=dir_save*\"test_\\$idx.hdf5\"\n",
    "\n",
    "# reading of input parameters\n",
    "alm = npzread(alm_path)\n",
    "blm = npzread(blm_path)\n",
    "        \n",
    "# Healpix-related parameters\n",
    "npix = nside2npix(nside)\n",
    "res = Resolution(nside)\n",
    "lmax = 3nside-1\n",
    "\n",
    "# Get unique θ value determined by nside\n",
    "unique_θ = unique_theta(npix, res);\n",
    "\n",
    "# Perform preconvolution\n",
    "FFTConv_demo_onlyT(alm, blm, unique_θ, lmax, nside, idx, dir)\n",
    "\"\"\" )\n",
    "end\n",
    "\n",
    "open( \"job_convolve.sh\", \"w\" ) do fp\n",
    "    \n",
    "write( fp, \"\"\"\n",
    "script=convolve_T.jl\n",
    "count=1\n",
    "nside=$nside\n",
    "dir=$dir_path\n",
    "alm_path=$alm_path \n",
    "blm_path=$blm_path \n",
    "countstop=\\$(($nside*4-1))\n",
    "for i in `seq  1 \\$countstop`\n",
    "do\n",
    "    if [ \\$(( \\$count % 10 )) -eq 0 ] ; then\n",
    "    sleep 1\n",
    "    echo \"sleep!\"\n",
    "    fi\n",
    "    bsub -q cmb_px julia \\$script \\$i \\$nside \\$dir \\$alm_path \\$blm_path \n",
    "    count=\\$((++count)) \n",
    "done\n",
    "\"\"\" )\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc1a918",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(`bash job_convolve.sh`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c66b0",
   "metadata": {},
   "source": [
    "### Specify sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31e97a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hz=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91106a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open( \"scan_T.jl\", \"w\" ) do fp\n",
    "    \n",
    "write( fp, \"\"\"using Condor\n",
    "using NPZ\n",
    "using Healpix\n",
    "using DataFrames\n",
    "using Falcons\n",
    "using PyCall\n",
    "np=pyimport(\"numpy\")\n",
    "\n",
    "# standard input\n",
    "idx=parse(Int64, ARGS[1]) # Specifies a piece of sky with unique θ\n",
    "nside = parse(Int64, ARGS[2]) # Specify nside\n",
    "dir_save = ARGS[3] # Specify preconvolved-map path\n",
    "Hz=parse(Int64, ARGS[4]) # Specify Hz of scan\n",
    "        \n",
    "# path of save file\n",
    "dir=dir_save*\"test_\\$idx.hdf5\"\n",
    "dir_map=dir_save*\"test_map=\\$idx=\\$nside=\\$Hz\"\n",
    "\n",
    "# Healpix-related parameters\n",
    "npix = nside2npix(nside)\n",
    "res = Resolution(nside)\n",
    "lmax = 3nside-1\n",
    "\n",
    "# Falcons-related parameters\n",
    "ss = gen_ScanningStrategy()\n",
    "day = 60 * 60 * 24\n",
    "year = day * 365\n",
    "ss.nside = nside\n",
    "ss.duration = year #[sec]\n",
    "ss.sampling_rate = Hz #[Hz]\n",
    "ss.alpha = 45 #[degree]\n",
    "ss.beta = 50 #[degree]\n",
    "ss.prec_rpm = period2rpm(192.348)\n",
    "ss.spin_rpm = 0.05 #[rpm]\n",
    "ss.hwp_rpm = 0.0 #[rpm]\n",
    "ss.start_point = \"pole\" #You can choose \"pole\" or \"equator\"\n",
    "ss.coord=\"G\"  # \n",
    "ss.FP_theta = [0.7378010233475734] #[target_det.theta[1]]\n",
    "ss.FP_phi = [59.808181651844826] #[target_det.phi[1]] .+ 30\n",
    "\n",
    "d_var , h= get_psi_make_TOD_T(ss, division = 1600, idx = idx, map_div=4, dir=dir)\n",
    "\n",
    "np.save(dir_map, d_var[:,1])\n",
    "\n",
    "#run(`rm \\$dir`)\n",
    "\"\"\" )\n",
    "end\n",
    "\n",
    "open( \"job_scan.sh\", \"w\" ) do fp\n",
    "    \n",
    "write( fp, \"\"\"\n",
    "script=scan_T.jl\n",
    "count=1\n",
    "nside=$nside\n",
    "dir=$dir_path\n",
    "Hz=$Hz\n",
    "countstop=\\$(($nside*4-1))\n",
    "for i in `seq  1 countstop`\n",
    "do\n",
    "    if [ \\$(( \\$count % 10 )) -eq 0 ] ; then\n",
    "    sleep 1\n",
    "    echo \"sleep!\"\n",
    "    fi\n",
    "    bsub -q l julia \\$script \\$i \\$nside \\$dir \\$Hz\n",
    "    count=\\$((++count)) \n",
    "done\n",
    "\"\"\" )\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9513d156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <60522458> is submitted to queue <cmb_px>.\n",
      "Job <60522459> is submitted to queue <cmb_px>.\n",
      "Job <60522462> is submitted to queue <cmb_px>.\n",
      "Job <60522464> is submitted to queue <cmb_px>.\n",
      "Job <60522466> is submitted to queue <cmb_px>.\n",
      "Job <60522469> is submitted to queue <cmb_px>.\n",
      "Job <60522471> is submitted to queue <cmb_px>.\n",
      "Job <60522474> is submitted to queue <cmb_px>.\n",
      "Job <60522475> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522484> is submitted to queue <cmb_px>.\n",
      "Job <60522487> is submitted to queue <cmb_px>.\n",
      "Job <60522489> is submitted to queue <cmb_px>.\n",
      "Job <60522491> is submitted to queue <cmb_px>.\n",
      "Job <60522494> is submitted to queue <cmb_px>.\n",
      "Job <60522496> is submitted to queue <cmb_px>.\n",
      "Job <60522499> is submitted to queue <cmb_px>.\n",
      "Job <60522501> is submitted to queue <cmb_px>.\n",
      "Job <60522503> is submitted to queue <cmb_px>.\n",
      "Job <60522506> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522517> is submitted to queue <cmb_px>.\n",
      "Job <60522519> is submitted to queue <cmb_px>.\n",
      "Job <60522521> is submitted to queue <cmb_px>.\n",
      "Job <60522524> is submitted to queue <cmb_px>.\n",
      "Job <60522525> is submitted to queue <cmb_px>.\n",
      "Job <60522527> is submitted to queue <cmb_px>.\n",
      "Job <60522529> is submitted to queue <cmb_px>.\n",
      "Job <60522530> is submitted to queue <cmb_px>.\n",
      "Job <60522532> is submitted to queue <cmb_px>.\n",
      "Job <60522534> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522538> is submitted to queue <cmb_px>.\n",
      "Job <60522540> is submitted to queue <cmb_px>.\n",
      "Job <60522542> is submitted to queue <cmb_px>.\n",
      "Job <60522543> is submitted to queue <cmb_px>.\n",
      "Job <60522545> is submitted to queue <cmb_px>.\n",
      "Job <60522546> is submitted to queue <cmb_px>.\n",
      "Job <60522549> is submitted to queue <cmb_px>.\n",
      "Job <60522551> is submitted to queue <cmb_px>.\n",
      "Job <60522553> is submitted to queue <cmb_px>.\n",
      "Job <60522554> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522561> is submitted to queue <cmb_px>.\n",
      "Job <60522564> is submitted to queue <cmb_px>.\n",
      "Job <60522566> is submitted to queue <cmb_px>.\n",
      "Job <60522568> is submitted to queue <cmb_px>.\n",
      "Job <60522570> is submitted to queue <cmb_px>.\n",
      "Job <60522571> is submitted to queue <cmb_px>.\n",
      "Job <60522573> is submitted to queue <cmb_px>.\n",
      "Job <60522575> is submitted to queue <cmb_px>.\n",
      "Job <60522579> is submitted to queue <cmb_px>.\n",
      "Job <60522581> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522585> is submitted to queue <cmb_px>.\n",
      "Job <60522587> is submitted to queue <cmb_px>.\n",
      "Job <60522588> is submitted to queue <cmb_px>.\n",
      "Job <60522590> is submitted to queue <cmb_px>.\n",
      "Job <60522591> is submitted to queue <cmb_px>.\n",
      "Job <60522593> is submitted to queue <cmb_px>.\n",
      "Job <60522595> is submitted to queue <cmb_px>.\n",
      "Job <60522596> is submitted to queue <cmb_px>.\n",
      "Job <60522598> is submitted to queue <cmb_px>.\n",
      "Job <60522599> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522606> is submitted to queue <cmb_px>.\n",
      "Job <60522608> is submitted to queue <cmb_px>.\n",
      "Job <60522610> is submitted to queue <cmb_px>.\n",
      "Job <60522611> is submitted to queue <cmb_px>.\n",
      "Job <60522613> is submitted to queue <cmb_px>.\n",
      "Job <60522615> is submitted to queue <cmb_px>.\n",
      "Job <60522616> is submitted to queue <cmb_px>.\n",
      "Job <60522618> is submitted to queue <cmb_px>.\n",
      "Job <60522620> is submitted to queue <cmb_px>.\n",
      "Job <60522622> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522626> is submitted to queue <cmb_px>.\n",
      "Job <60522628> is submitted to queue <cmb_px>.\n",
      "Job <60522630> is submitted to queue <cmb_px>.\n",
      "Job <60522631> is submitted to queue <cmb_px>.\n",
      "Job <60522633> is submitted to queue <cmb_px>.\n",
      "Job <60522634> is submitted to queue <cmb_px>.\n",
      "Job <60522636> is submitted to queue <cmb_px>.\n",
      "Job <60522638> is submitted to queue <cmb_px>.\n",
      "Job <60522639> is submitted to queue <cmb_px>.\n",
      "Job <60522641> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522646> is submitted to queue <cmb_px>.\n",
      "Job <60522647> is submitted to queue <cmb_px>.\n",
      "Job <60522649> is submitted to queue <cmb_px>.\n",
      "Job <60522650> is submitted to queue <cmb_px>.\n",
      "Job <60522652> is submitted to queue <cmb_px>.\n",
      "Job <60522654> is submitted to queue <cmb_px>.\n",
      "Job <60522655> is submitted to queue <cmb_px>.\n",
      "Job <60522657> is submitted to queue <cmb_px>.\n",
      "Job <60522658> is submitted to queue <cmb_px>.\n",
      "Job <60522659> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522664> is submitted to queue <cmb_px>.\n",
      "Job <60522666> is submitted to queue <cmb_px>.\n",
      "Job <60522668> is submitted to queue <cmb_px>.\n",
      "Job <60522670> is submitted to queue <cmb_px>.\n",
      "Job <60522672> is submitted to queue <cmb_px>.\n",
      "Job <60522673> is submitted to queue <cmb_px>.\n",
      "Job <60522675> is submitted to queue <cmb_px>.\n",
      "Job <60522676> is submitted to queue <cmb_px>.\n",
      "Job <60522678> is submitted to queue <cmb_px>.\n",
      "Job <60522679> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522684> is submitted to queue <cmb_px>.\n",
      "Job <60522686> is submitted to queue <cmb_px>.\n",
      "Job <60522687> is submitted to queue <cmb_px>.\n",
      "Job <60522689> is submitted to queue <cmb_px>.\n",
      "Job <60522691> is submitted to queue <cmb_px>.\n",
      "Job <60522692> is submitted to queue <cmb_px>.\n",
      "Job <60522694> is submitted to queue <cmb_px>.\n",
      "Job <60522695> is submitted to queue <cmb_px>.\n",
      "Job <60522697> is submitted to queue <cmb_px>.\n",
      "Job <60522699> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522703> is submitted to queue <cmb_px>.\n",
      "Job <60522705> is submitted to queue <cmb_px>.\n",
      "Job <60522706> is submitted to queue <cmb_px>.\n",
      "Job <60522708> is submitted to queue <cmb_px>.\n",
      "Job <60522710> is submitted to queue <cmb_px>.\n",
      "Job <60522711> is submitted to queue <cmb_px>.\n",
      "Job <60522713> is submitted to queue <cmb_px>.\n",
      "Job <60522714> is submitted to queue <cmb_px>.\n",
      "Job <60522716> is submitted to queue <cmb_px>.\n",
      "Job <60522718> is submitted to queue <cmb_px>.\n",
      "sleep!\n",
      "Job <60522722> is submitted to queue <cmb_px>.\n",
      "Job <60522725> is submitted to queue <cmb_px>.\n",
      "Job <60522727> is submitted to queue <cmb_px>.\n",
      "Job <60522728> is submitted to queue <cmb_px>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mbash\u001b[24m \u001b[4mjob_sample.sh\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`bash job_scan.sh`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c5c367",
   "metadata": {},
   "source": [
    "### Make a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ace8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_test = zeros(npix)\n",
    "for i in 1:4nside-1\n",
    "    try\n",
    "        temp = npzread(dir_path*\"/test_map=$i=$nside=$Hz\"*\".npy\")\n",
    "        pixmin,pixmax=unique_theta_detect(i, nside,npix)\n",
    "        map_test[pixmin:pixmax] = real(temp[:,1])\n",
    "    catch\n",
    "        println(\"$i\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "406a9828",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.mollview(np.log10(map_test), cmap = \"coolwarm\", min=0,max=3, rot = (0,0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
